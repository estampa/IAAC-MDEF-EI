{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1yUcSgd27m"
      },
      "source": [
        "# Accessing an API\n",
        "\n",
        "We will use https://replicate.com services through an API. Since we are not running AI tools in colab we don't need a GPU runtime.\n",
        "\n",
        "⚡ You have to login using your github account, it is free to a (unknown) limit.\n",
        "\n",
        "To use an API you have to provide some kind of verification, and it is mainly done using **tokens**. Tokens are strings of characters attached to your account in the service, you have to keep them \"secret\". ⚡ So we need to create a replicate token here https://replicate.com/account/api-tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwiNe7DwCS-1"
      },
      "source": [
        "⚡ Then you can check the documentation about accessing the API here https://replicate.com/docs/get-started/python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚡ Then search for the service that you want to use here https://replicate.com/explore. For this example we are going to use the [Llama language model](https://replicate.com/meta/llama-2-13b-chat/). We can check its API usage in the API tab, selecting python as the programming language ([link](https://replicate.com/meta/llama-2-13b-chat/api?tab=python))."
      ],
      "metadata": {
        "id": "XDTJLGwG1eIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps"
      ],
      "metadata": {
        "id": "VEYnTWOL8pvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we install the library for accessing the API."
      ],
      "metadata": {
        "id": "yxqDfdomsA6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q replicate datasets"
      ],
      "metadata": {
        "id": "SvOI4TDZJMKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "\n",
        "api_token='YOUR_REPLICATE_TOKEN_HERE'\n",
        "\n",
        "client = replicate.Client(api_token=api_token)"
      ],
      "metadata": {
        "id": "Ciyjx36O9b8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each model have different parameters. Llama has a system prompt, that defines the role of the LLM and a prompt that is the instruction or example. You can check the parameters on the [API tab](https://replicate.com/meta/llama-2-13b-chat/api).\n",
        "\n",
        "Some work is required to craft the system prompt and the prompt, and there is a lot of trial an error. There are lot's of online resources online.\n",
        "\n",
        "Now we will use another LLM, [Mistral-7B-Instruct v0.2](https://replicate.com/mistralai/mistral-7b-instruct-v0.2) to generate image prompts using a complex prompt."
      ],
      "metadata": {
        "id": "ZH32k9g3evZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image_prompt(dream):\n",
        "\n",
        "  prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "  ### Instruction:\n",
        "  You are an excellent Stable diffusion prompt writer. Given a one-sentence story, you can write a Stable diffusion prompt.\n",
        "  Instructions for writing a Stable diffusion prompt with a one-sentence story:\n",
        "  • Use specific descriptors based on the one-sentence story details (e.g., \"dense pine forest\" instead of \"forest\").\n",
        "  • Detail objects mentioned in the one-sentence story (e.g., \"ancient leather-bound book\" instead of \"book\").\n",
        "  • Highlight emotions conveyed in the one-sentence story (e.g., \"melancholic,\" \"joyful\").\n",
        "  • Choose a visual style, such as \"35mm film,\" \"cinematic,\" \"watercolor\", \"oil painting\", \"3D art\".\n",
        "  • Reference an artist or artistic style that aligns with the one-sentence story vibe.\n",
        "\n",
        "  Examples of Stable diffusion prompts:\n",
        "  • \"Macie Grey in a Victorian dress, exploring a luminous garden with glowing plants and mystical creatures, rendered in a dreamy watercolor style with soft pastel hues.\"\n",
        "  • \"Mark Hamel as an astronaut in a futuristic suit, examining an ancient monolith amidst ruins on an alien planet, captured with a 35mm film grain effect and a surreal, otherworldly color palette.\"\n",
        "  • \"Baby shark with a painted face on an old wall, in the style of hyper-realistic sculptures, fragmented figures, distressed materials, tiled walls of light grays, cracked, rococo—inspired art\"\n",
        "  • \"Award-winning cinematic bioluminescent oil creature design in gold, vibrant holographic gradient blue and silver colored scheme, in the style 3d hydro — drip venom character, ray tracing reflection, prismatic lighting, realistic texture detail, vibrant electric flames coursing through oil\"\n",
        "  • \"Pope Francis wearing leather jacket is a DJ in a nightclub, mixing live on stage, giant mixing table, 4k resolution, a masterpiece\"\n",
        "  • \"Kanye West in medieval armor, standing on a cliff's edge, watching a dragon soar from misty mountains, depicted in a Renaissance painting style with dramatic chiaroscuro lighting.\"\n",
        "  • \"A trench-coated Dick Tracy, silhouette against neon noir streets, searching for elusive clues of a jewel thief, visualized in a vibrant neon noir style with rain-soaked streets reflecting the city's lights.\"\n",
        "\n",
        "  Dream description: {dream}\n",
        "\n",
        "  ### Response:\"\"\"\n",
        "\n",
        "  output = client.run(\n",
        "      \"mistralai/mistral-7b-instruct-v0.2\",\n",
        "      input={\n",
        "          \"prompt\": prompt,\n",
        "          \"max_new_tokens\": 256,\n",
        "          \"prompt_template\": \"<s>[INST] {prompt} [/INST] \",\n",
        "      },\n",
        "  )\n",
        "\n",
        "  image_prompt = \"\".join(output)\n",
        "\n",
        "  return image_prompt"
      ],
      "metadata": {
        "id": "CiNrbFwxg6vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"DReAMy-lib/DreamBank-dreams-en\")"
      ],
      "metadata": {
        "id": "eCNny68Eo0em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_dreams = dataset['train']['dreams'][0:5]\n",
        "\n",
        "image_prompts = []\n",
        "\n",
        "for dream in first_dreams:\n",
        "  print(dream)\n",
        "  image_prompt = create_image_prompt(dream)\n",
        "  print(image_prompt)\n",
        "\n",
        "  image_prompts.append(image_prompt)"
      ],
      "metadata": {
        "id": "mLtxyD4JpAfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_prompt in image_prompts:\n",
        "  print(image_prompt)"
      ],
      "metadata": {
        "id": "LZTrALVfrAbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean the image prompt\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_prompt(prompt):\n",
        "\n",
        "  # https://stackoverflow.com/a/49146722/330558\n",
        "  def remove_emoji(string):\n",
        "      emoji_pattern = re.compile(\"[\"\n",
        "                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            u\"\\U00002702-\\U000027B0\"\n",
        "                            u\"\\U000024C2-\\U0001F251\"\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "      return emoji_pattern.sub(r'', string)\n",
        "\n",
        "  clean_image_prompt = remove_emoji(image_prompt)\n",
        "  # text_between_quotes = re.findall('\"([^\"]*)\"', clean_image_prompt)\n",
        "  # if len(text_between_quotes) > 0:\n",
        "  #   clean_image_prompt = text_between_quotes[0]\n",
        "  print(clean_image_prompt)\n",
        "\n",
        "  return clean_image_prompt"
      ],
      "metadata": {
        "id": "C-99fc2lk8HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_image_prompts = []\n",
        "for image_prompt in image_prompts:\n",
        "  clean_image_prompts = clean_prompt(image_prompt)"
      ],
      "metadata": {
        "id": "PTD6lJv0qIyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(image_prompt):\n",
        "  output = client.run(\n",
        "      \"stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b\",\n",
        "      input={\n",
        "          \"width\": 768,\n",
        "          \"height\": 768,\n",
        "          \"prompt\": image_prompt,\n",
        "          \"num_outputs\": 1,\n",
        "      }\n",
        "  )\n",
        "\n",
        "  image_url = output[0]\n",
        "  image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "_vrkMHpikQuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "for clean_image_prompt in clean_image_prompts:\n",
        "  image = generate_image(clean_image_prompt)\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "AYQk3fSUrU7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output is a list of URLs to images, so we iterate it downloading and displaying the image."
      ],
      "metadata": {
        "id": "H4cDOTOLnhEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "for url in output:\n",
        "  image = Image.open(requests.get(url, stream=True).raw)\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "9IkhWRuim5NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tgbkOxbkf8B"
      },
      "source": [
        "# Finalizing\n",
        "\n",
        "When you finish working you have to remember to **stop the runtime**, because there is a time limit and to avoid wasting resources. To stop the runtime click Manage Sessions on the Runtime menu. Once the dialog opens click terminate on the current runtime.\n",
        "\n",
        "> But when you stop the runtime everything you have not saved is ⚠ **lost** ⚠, so be sure to **download** everything you want to keep before stopping it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNi8VV-wJDFi"
      },
      "source": [
        "# Credits\n",
        "\n",
        "Taller Estampa https://tallerestampa.com / https://github.com/estampa\n"
      ]
    }
  ]
}