{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1yUcSgd27m"
      },
      "source": [
        "# Datasets and automation\n",
        "\n",
        "In the notebook we will access a dataset and process it's content using multip`le chained APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing the Dataset"
      ],
      "metadata": {
        "id": "VEYnTWOL8pvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we install the library for accessing the dataset."
      ],
      "metadata": {
        "id": "yxqDfdomsA6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "SvOI4TDZJMKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can load datsets from huggingface using their name. In this example we are going to load the [DreamBank dreams dataset](https://huggingface.co/datasets/DReAMy-lib/DreamBank-dreams-en)."
      ],
      "metadata": {
        "id": "7KCQLOJfPhs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"DReAMy-lib/DreamBank-dreams-en\")"
      ],
      "metadata": {
        "id": "eCNny68Eo0em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each dataset has it's own structure, so we first print it."
      ],
      "metadata": {
        "id": "SV9tn7WXQOWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "qb-qFivXQN-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case there is a subset called 'train' with 5 features for each of the 22415 entries. We are interested in the 'dreams' feature, and to see their content we print the first 5."
      ],
      "metadata": {
        "id": "ojO0kSaJQhSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_dreams = 5\n",
        "\n",
        "for idx in range(number_of_dreams):\n",
        "  print(dataset['train']['dreams'][idx])"
      ],
      "metadata": {
        "id": "8ndo-h8eRACB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the dataset with the API"
      ],
      "metadata": {
        "id": "XSVlcAEVSCRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install the library for accessing the replicate API"
      ],
      "metadata": {
        "id": "Z4Fq6yg-SVbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q replicate"
      ],
      "metadata": {
        "id": "v6kr_FxTSBxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "\n",
        "api_token='<paste-your-token-here>'\n",
        "\n",
        "client = replicate.Client(api_token=api_token)"
      ],
      "metadata": {
        "id": "Ciyjx36O9b8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the dataset, we want to convert the dream descriptions into image prompts, and to do that we use the LLM [Llama 3 8b Instruct](https://replicate.com/meta/meta-llama-3-8b-instruct/api).\n",
        "\n",
        "What we have to do is to create a text prompt that creates the image prompt from the description. In the case of Llama there is also the system prompt that describes the role of the LLM. There is a lot of trial an error in the process.\n",
        "\n",
        "Apart from the prompts, there are more parameters, you check the [API tab](https://replicate.com/meta/meta-llama-3-8b-instruct/api)."
      ],
      "metadata": {
        "id": "8ldNWT4IS_VL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image_prompt(dream):\n",
        "\n",
        "  prompt = f\"\"\"Below is an instruction that describes a task. Write a short response that appropriately completes the request.\n",
        "\n",
        "  ### Instruction:\n",
        "  You are an excellent Stable diffusion prompt writer. Given a one-sentence story, you can write a Stable diffusion prompt.\n",
        "  Instructions for writing a Stable diffusion prompt with a one-sentence story:\n",
        "  • Use specific descriptors based on the one-sentence story details (e.g., \"dense pine forest\" instead of \"forest\").\n",
        "  • Detail objects mentioned in the one-sentence story (e.g., \"ancient leather-bound book\" instead of \"book\").\n",
        "  • Highlight emotions conveyed in the one-sentence story (e.g., \"melancholic,\" \"joyful\").\n",
        "  • Choose a visual style, such as \"35mm film,\" \"cinematic,\" \"watercolor\", \"oil painting\", \"3D art\".\n",
        "  • Reference an artist or artistic style that aligns with the one-sentence story vibe.\n",
        "  • Output only the prompt without any explanation\n",
        "\n",
        "  Examples of Stable diffusion prompts:\n",
        "  • \"Macie Grey in a Victorian dress, exploring a luminous garden with glowing plants and mystical creatures, rendered in a dreamy watercolor style with soft pastel hues.\"\n",
        "  • \"Mark Hamel as an astronaut in a futuristic suit, examining an ancient monolith amidst ruins on an alien planet, captured with a 35mm film grain effect and a surreal, otherworldly color palette.\"\n",
        "  • \"Baby shark with a painted face on an old wall, in the style of hyper-realistic sculptures, fragmented figures, distressed materials, tiled walls of light grays, cracked, rococo—inspired art\"\n",
        "  • \"Award-winning cinematic bioluminescent oil creature design in gold, vibrant holographic gradient blue and silver colored scheme, in the style 3d hydro — drip venom character, ray tracing reflection, prismatic lighting, realistic texture detail, vibrant electric flames coursing through oil\"\n",
        "  • \"Pope Francis wearing leather jacket is a DJ in a nightclub, mixing live on stage, giant mixing table, 4k resolution, a masterpiece\"\n",
        "  • \"Kanye West in medieval armor, standing on a cliff's edge, watching a dragon soar from misty mountains, depicted in a Renaissance painting style with dramatic chiaroscuro lighting.\"\n",
        "  • \"A trench-coated Dick Tracy, silhouette against neon noir streets, searching for elusive clues of a jewel thief, visualized in a vibrant neon noir style with rain-soaked streets reflecting the city's lights.\"\n",
        "\n",
        "  Dream description: {dream}\n",
        "\n",
        "  ### Response:\"\"\"\n",
        "\n",
        "  input = {\n",
        "      \"system_prompt string\": \"You are a helpful AI assistant.\",\n",
        "      \"prompt\": prompt,\n",
        "      \"max_new_tokens\": 256,\n",
        "      \"prompt_template\": \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "  }\n",
        "\n",
        "  output = client.run(\n",
        "      \"meta/meta-llama-3-8b-instruct\",\n",
        "      input=input\n",
        "  )\n",
        "\n",
        "  image_prompt = \"\".join(output)\n",
        "\n",
        "  return image_prompt"
      ],
      "metadata": {
        "id": "CiNrbFwxg6vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_dreams = 5\n",
        "\n",
        "first_dreams = dataset['train']['dreams'][0:number_of_dreams]\n",
        "\n",
        "image_prompts = []\n",
        "\n",
        "for dream in first_dreams:\n",
        "  print(\"Dream:\", dream)\n",
        "  image_prompt = create_image_prompt(dream)\n",
        "  print(\"Prompt:\", image_prompt)\n",
        "  print(\"\")\n",
        "\n",
        "  image_prompts.append(image_prompt)"
      ],
      "metadata": {
        "id": "mLtxyD4JpAfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the images"
      ],
      "metadata": {
        "id": "bHtfZtGtk1UD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean the image prompt\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_prompt(prompt):\n",
        "\n",
        "  # https://stackoverflow.com/a/49146722/330558\n",
        "  def remove_emoji(string):\n",
        "      emoji_pattern = re.compile(\"[\"\n",
        "                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            u\"\\U00002702-\\U000027B0\"\n",
        "                            u\"\\U000024C2-\\U0001F251\"\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "      return emoji_pattern.sub(r'', string)\n",
        "\n",
        "  clean_image_prompt = remove_emoji(image_prompt)\n",
        "  # text_between_quotes = re.findall('\"([^\"]*)\"', clean_image_prompt)\n",
        "  # if len(text_between_quotes) > 0:\n",
        "  #   clean_image_prompt = text_between_quotes[0]\n",
        "  print(clean_image_prompt)\n",
        "\n",
        "  return clean_image_prompt"
      ],
      "metadata": {
        "id": "C-99fc2lk8HA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_image_prompts = []\n",
        "for image_prompt in image_prompts:\n",
        "  clean_image_prompts.append(clean_prompt(image_prompt))"
      ],
      "metadata": {
        "id": "PTD6lJv0qIyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(image_prompt):\n",
        "  input = {\n",
        "    \"prompt\": image_prompt,\n",
        "    \"megapixels\": \"0.25\"\n",
        "  }\n",
        "\n",
        "  output = client.run(\n",
        "    \"black-forest-labs/flux-schnell\",\n",
        "    input=input\n",
        "  )\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "_vrkMHpikQuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "images = []\n",
        "for clean_image_prompt in tqdm(clean_image_prompts):\n",
        "  image = generate_image(clean_image_prompt)\n",
        "  images.append(image)"
      ],
      "metadata": {
        "id": "AYQk3fSUrU7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we display the images."
      ],
      "metadata": {
        "id": "H4cDOTOLnhEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "for image_url in images:\n",
        "  image = Image.open(requests.get(image_url[0], stream=True).raw)\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "9IkhWRuim5NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tgbkOxbkf8B"
      },
      "source": [
        "# Finalizing\n",
        "\n",
        "When you finish working you have to remember to **stop the runtime**, because there is a time limit and to avoid wasting resources. To stop the runtime click Manage Sessions on the Runtime menu. Once the dialog opens click terminate on the current runtime.\n",
        "\n",
        "> But when you stop the runtime everything you have not saved is ⚠ **lost** ⚠, so be sure to **download** everything you want to keep before stopping it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNi8VV-wJDFi"
      },
      "source": [
        "# Credits\n",
        "\n",
        "Taller Estampa https://tallerestampa.com / https://github.com/estampa\n"
      ]
    }
  ]
}